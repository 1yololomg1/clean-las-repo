{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8423fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T05:36:46.656367Z",
     "iopub.status.busy": "2026-01-04T05:36:46.656026Z",
     "iopub.status.idle": "2026-01-04T05:36:50.686323Z",
     "shell.execute_reply": "2026-01-04T05:36:50.685282Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 4.038915,
     "end_time": "2026-01-04T05:36:50.689028",
     "exception": false,
     "start_time": "2026-01-04T05:36:46.650113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FAST VOCABULARY EXTRACTOR\n",
      "============================================================\n",
      "Loaded 1561 training sentences\n",
      "\n",
      "--- Method 1: Sentence Co-occurrence ---\n",
      "Found 2532 words with >=30% confidence\n",
      "\n",
      "--- Method 2: Positional Extraction ---\n",
      "Found 192 words from positional analysis\n",
      "\n",
      "============================================================\n",
      "MERGED VOCABULARY: 2536 words\n",
      "============================================================\n",
      "\n",
      "--- Method 3: High-Frequency Unknowns ---\n",
      "Found 1 high-frequency unknowns (>=5 occurrences)\n",
      "\n",
      "============================================================\n",
      "HIGH-CONFIDENCE VOCABULARY (>=40%)\n",
      "Copy this into VOCABULARY dict in mycelial_translator.py\n",
      "============================================================\n",
      "\n",
      "# HIGH CONFIDENCE (>=40%)\n",
      "    'ma-na': {'meaning': 'silver', 'type': 'material', 'confidence': 0.84},  # 757x\n",
      "    'um-ma': {'meaning': 'silver', 'type': 'material', 'confidence': 0.79},  # 541x\n",
      "    'lá': {'meaning': 'silver', 'type': 'material', 'confidence': 0.78},  # 415x\n",
      "    'qí-bi-ma': {'meaning': 'silver', 'type': 'material', 'confidence': 0.81},  # 309x\n",
      "    'šu-ma': {'meaning': 'silver', 'type': 'material', 'confidence': 0.79},  # 301x\n",
      "    'ki-ma': {'meaning': 'silver', 'type': 'material', 'confidence': 0.79},  # 262x\n",
      "    'a-lá-ḫi-im': {'meaning': 'ali', 'type': 'unknown', 'confidence': 0.95},  # 254x\n",
      "    'iš-tù': {'meaning': 'silver', 'type': 'material', 'confidence': 0.84},  # 240x\n",
      "    'a-lim(ki)': {'meaning': 'city', 'type': 'unknown', 'confidence': 0.94},  # 227x\n",
      "    'iš-tí': {'meaning': 'silver', 'type': 'material', 'confidence': 0.8},  # 205x\n",
      "    'lu': {'meaning': 'silver', 'type': 'material', 'confidence': 0.84},  # 197x\n",
      "    'ṣa-ru-pá-am': {'meaning': 'silver', 'type': 'material', 'confidence': 0.99},  # 182x\n",
      "    'mì-ma': {'meaning': 'silver', 'type': 'material', 'confidence': 0.75},  # 182x\n",
      "    'ší-im': {'meaning': 'silver', 'type': 'material', 'confidence': 0.86},  # 173x\n",
      "    'ṭup-pá-am': {'meaning': 'tablet', 'type': 'unknown', 'confidence': 0.9},  # 173x\n",
      "    'a-ta': {'meaning': 'silver', 'type': 'material', 'confidence': 0.78},  # 162x\n",
      "    'ma-lá': {'meaning': 'silver', 'type': 'material', 'confidence': 0.75},  # 158x\n",
      "    'a-dí': {'meaning': 'silver', 'type': 'material', 'confidence': 0.8},  # 156x\n",
      "    'a-ma-kam': {'meaning': 'there', 'type': 'unknown', 'confidence': 0.97},  # 148x\n",
      "    'a-na-kam': {'meaning': 'here', 'type': 'unknown', 'confidence': 0.96},  # 138x\n",
      "    'en-um-a-šur': {'meaning': 'ennam', 'type': 'unknown', 'confidence': 0.94},  # 136x\n",
      "    'qí-bi₄-ma': {'meaning': 'silver', 'type': 'material', 'confidence': 0.78},  # 131x\n",
      "    'i-ṣé-er': {'meaning': 'silver', 'type': 'material', 'confidence': 0.82},  # 122x\n",
      "    'a-nim': {'meaning': 'silver', 'type': 'material', 'confidence': 0.77},  # 122x\n",
      "    'kà-ru-um': {'meaning': 'colony', 'type': 'unknown', 'confidence': 0.92},  # 116x\n",
      "    'a-na-ku': {'meaning': 'silver', 'type': 'material', 'confidence': 0.81},  # 115x\n",
      "    'i-ša-qal': {'meaning': 'pay', 'type': 'unknown', 'confidence': 0.9},  # 113x\n",
      "    'šu-IŠTAR': {'meaning': 'tar', 'type': 'unknown', 'confidence': 0.88},  # 113x\n",
      "    'SIG₅': {'meaning': 'good', 'type': 'quality', 'confidence': 0.69},  # 111x\n",
      "    'a-mur-IŠTAR': {'meaning': 'amur', 'type': 'unknown', 'confidence': 0.93},  # 111x\n",
      "    'i-šu': {'meaning': 'silver', 'type': 'material', 'confidence': 0.82},  # 108x\n",
      "    'a-ḫa-ma': {'meaning': 'silver', 'type': 'material', 'confidence': 0.81},  # 107x\n",
      "    'li-mu-um': {'meaning': 'month', 'type': 'unknown', 'confidence': 0.89},  # 106x\n",
      "    'en-na-sú-in': {'meaning': 'suen', 'type': 'unknown', 'confidence': 0.91},  # 105x\n",
      "    'en-um-a-šùr': {'meaning': 'ennam', 'type': 'unknown', 'confidence': 0.93},  # 103x\n",
      "    'a-ḫi': {'meaning': 'brother', 'type': 'relation', 'confidence': 0.98},  # 103x\n",
      "    'en-nam-a-šur': {'meaning': 'ennam', 'type': 'unknown', 'confidence': 0.95},  # 103x\n",
      "    'kà-ri-im': {'meaning': 'colony', 'type': 'unknown', 'confidence': 0.73},  # 99x\n",
      "    'a-wa-tim': {'meaning': 'these', 'type': 'unknown', 'confidence': 0.72},  # 95x\n",
      "    'a-tù-nu': {'meaning': 'silver', 'type': 'material', 'confidence': 0.79},  # 95x\n",
      "    'ú-lá': {'meaning': 'silver', 'type': 'material', 'confidence': 0.75},  # 95x\n",
      "    'kà-ni-iš': {'meaning': 'kanesh', 'type': 'unknown', 'confidence': 0.92},  # 94x\n",
      "    'ku-nu-ki-a': {'meaning': 'seal', 'type': 'unknown', 'confidence': 0.88},  # 94x\n",
      "    'GÍR': {'meaning': 'dagger', 'type': 'unknown', 'confidence': 0.96},  # 93x\n",
      "    'ni-dí-in': {'meaning': 'gave', 'type': 'verb', 'confidence': 0.88},  # 93x\n",
      "    'ŠÀ.BA': {'meaning': 'silver', 'type': 'material', 'confidence': 0.84},  # 92x\n",
      "    'ša-lim-a-šùr': {'meaning': 'alim', 'type': 'unknown', 'confidence': 0.97},  # 90x\n",
      "    'a-ni-a-tim': {'meaning': 'these', 'type': 'unknown', 'confidence': 0.94},  # 89x\n",
      "    'il₅-qé': {'meaning': 'silver', 'type': 'material', 'confidence': 0.8},  # 88x\n",
      "    'a-dí-in': {'meaning': 'gave', 'type': 'verb', 'confidence': 0.79},  # 88x\n",
      "\n",
      "============================================================\n",
      "MEDIUM-CONFIDENCE VOCABULARY (30-40%)\n",
      "============================================================\n",
      "\n",
      "# MEDIUM CONFIDENCE (30-40%) - review before adding\n",
      "\n",
      "============================================================\n",
      "TOP UNKNOWNS (high frequency, not in vocab)\n",
      "These need manual investigation\n",
      "============================================================\n",
      "    'e': ???  # 54x\n",
      "\n",
      "Saved full vocabulary to extracted_vocab.json\n",
      "\n",
      "============================================================\n",
      "DONE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FAST VOCABULARY EXTRACTOR\n",
    "=========================\n",
    "Training-only version for quick iteration.\n",
    "Skips unlabeled data to run in seconds instead of minutes.\n",
    "\n",
    "Goal: Extract Akkadian→English word mappings from training pairs.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# Logograms we know - used as anchors\n",
    "LOGO_TO_ENGLISH = {\n",
    "    'KÙ.BABBAR': 'silver', 'KÙ.GI': 'gold', 'URUDU': 'copper',\n",
    "    'AN.NA': 'tin', 'GÍN': 'shekel', 'GÍN.TA': 'shekel',\n",
    "    'MA.NA': 'mina', 'GÚ': 'talent', 'DUMU': 'son',\n",
    "    'DUMU.MUNUS': 'daughter', 'DAM': 'wife', 'DAM.GÀR': 'merchant',\n",
    "    'KIŠIB': 'seal', 'É': 'house', 'ANŠE': 'donkey',\n",
    "    'TÚG': 'textile', 'TÚG.ḪI.A': 'textiles', 'UDU': 'sheep',\n",
    "    'SÍG': 'wool', 'SÍG.ḪI.A': 'wool', 'ITU': 'month',\n",
    "    'ITU.KAM': 'month', 'IGI': 'witness',\n",
    "}\n",
    "\n",
    "# Stop words to ignore\n",
    "AKK_STOP = {'ša', 'a-na', 'ù', 'ú', 'i-na', 'x', 'xx', 'xxx', '…'}\n",
    "ENG_STOP = {\n",
    "    'the', 'a', 'an', 'of', 'and', 'to', 'in', 'for', 'is', 'are',\n",
    "    'was', 'were', 'be', 'have', 'has', 'had', 'he', 'she', 'it',\n",
    "    'they', 'we', 'i', 'you', 'my', 'your', 'his', 'her', 'its',\n",
    "    'their', 'our', 'from', 'with', 'by', 'at', 'on', 'as', 'or',\n",
    "    'if', 'but', 'not', 'no', 'that', 'this', 'which', 'who',\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# HELPERS\n",
    "# ============================================================\n",
    "\n",
    "def is_number(w):\n",
    "    return bool(re.match(r'^[\\d.]+$', w))\n",
    "\n",
    "def is_logogram(w):\n",
    "    if w in LOGO_TO_ENGLISH:\n",
    "        return True\n",
    "    return re.sub(r'[₀-₉]', '', w) in LOGO_TO_ENGLISH\n",
    "\n",
    "def tokenize_akk(text):\n",
    "    return text.split()\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return re.findall(r\"[a-z]+(?:'[a-z]+)?|\\d+\", text.lower())\n",
    "\n",
    "# ============================================================\n",
    "# METHOD 1: SENTENCE CO-OCCURRENCE\n",
    "# ============================================================\n",
    "\n",
    "def extract_cooccurrence(train_df):\n",
    "    \"\"\"\n",
    "    Find Akkadian words that consistently appear with specific English words.\n",
    "    Simple but effective: if 'ṣa-ru-pá-am' appears in 80% of sentences \n",
    "    containing 'refined', they're probably related.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Method 1: Sentence Co-occurrence ---\")\n",
    "    \n",
    "    cooccur = defaultdict(Counter)\n",
    "    akk_counts = Counter()\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        akk_words = set(tokenize_akk(row['transliteration']))\n",
    "        eng_words = set(tokenize_eng(row['translation']))\n",
    "        \n",
    "        # Filter\n",
    "        akk_words = {w for w in akk_words if w not in AKK_STOP \n",
    "                     and not is_number(w) and not is_logogram(w) and len(w) > 1}\n",
    "        eng_words = {w for w in eng_words if w not in ENG_STOP and len(w) > 2}\n",
    "        \n",
    "        for akk in akk_words:\n",
    "            akk_counts[akk] += 1\n",
    "            for eng in eng_words:\n",
    "                cooccur[akk][eng] += 1\n",
    "    \n",
    "    # Build vocabulary with confidence scores\n",
    "    vocab = {}\n",
    "    for akk, eng_counts in cooccur.items():\n",
    "        if akk_counts[akk] < 3:  # Need at least 3 occurrences\n",
    "            continue\n",
    "        \n",
    "        total = akk_counts[akk]\n",
    "        top_eng, top_count = eng_counts.most_common(1)[0]\n",
    "        confidence = top_count / total\n",
    "        \n",
    "        if confidence >= 0.3 and top_count >= 3:\n",
    "            vocab[akk] = {\n",
    "                'translation': top_eng,\n",
    "                'confidence': round(confidence, 2),\n",
    "                'count': top_count,\n",
    "                'total': total,\n",
    "                'alternatives': eng_counts.most_common(5)[1:],\n",
    "            }\n",
    "    \n",
    "    # Sort by count\n",
    "    vocab = dict(sorted(vocab.items(), key=lambda x: -x[1]['count']))\n",
    "    \n",
    "    print(f\"Found {len(vocab)} words with >=30% confidence\")\n",
    "    return vocab\n",
    "\n",
    "# ============================================================\n",
    "# METHOD 2: POSITIONAL EXTRACTION (Flipped)\n",
    "# ============================================================\n",
    "\n",
    "def extract_positional(train_df):\n",
    "    \"\"\"\n",
    "    Extract vocabulary based on position relative to logograms.\n",
    "    Key insight: Akkadian post-LOGO maps to English pre-anchor (word order flip)\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Method 2: Positional Extraction ---\")\n",
    "    \n",
    "    # Track what appears at each position\n",
    "    akk_positions = defaultdict(lambda: defaultdict(Counter))\n",
    "    eng_positions = defaultdict(lambda: defaultdict(Counter))\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        akk_words = tokenize_akk(row['transliteration'])\n",
    "        eng_words = tokenize_eng(row['translation'])\n",
    "        \n",
    "        # Akkadian: find logograms and record neighbors\n",
    "        for i, w in enumerate(akk_words):\n",
    "            logo = None\n",
    "            if w in LOGO_TO_ENGLISH:\n",
    "                logo = w\n",
    "            elif re.sub(r'[₀-₉]', '', w) in LOGO_TO_ENGLISH:\n",
    "                logo = re.sub(r'[₀-₉]', '', w)\n",
    "            \n",
    "            if logo:\n",
    "                for offset in [-2, -1, 1, 2]:\n",
    "                    j = i + offset\n",
    "                    if 0 <= j < len(akk_words):\n",
    "                        neighbor = akk_words[j]\n",
    "                        if neighbor not in AKK_STOP and not is_number(neighbor) and not is_logogram(neighbor):\n",
    "                            pos = f\"post{offset}\" if offset > 0 else f\"pre{offset}\"\n",
    "                            akk_positions[logo][pos][neighbor] += 1\n",
    "        \n",
    "        # English: find anchors and record neighbors\n",
    "        for i, w in enumerate(eng_words):\n",
    "            for logo, anchor in LOGO_TO_ENGLISH.items():\n",
    "                if w == anchor or w == anchor + 's':  # Handle plurals\n",
    "                    for offset in [-2, -1, 1, 2]:\n",
    "                        j = i + offset\n",
    "                        if 0 <= j < len(eng_words):\n",
    "                            neighbor = eng_words[j]\n",
    "                            if neighbor not in ENG_STOP:\n",
    "                                pos = f\"post{offset}\" if offset > 0 else f\"pre{offset}\"\n",
    "                                eng_positions[anchor][pos][neighbor] += 1\n",
    "    \n",
    "    # Cross-reference with FLIPPED positions\n",
    "    # Akkadian post1 -> English pre-1 (descriptors come after in Akk, before in Eng)\n",
    "    position_map = {'post1': 'pre-1', 'post2': 'pre-2', 'pre-1': 'post1', 'pre-2': 'post2'}\n",
    "    \n",
    "    vocab = {}\n",
    "    \n",
    "    for logo, eng_anchor in LOGO_TO_ENGLISH.items():\n",
    "        if logo not in akk_positions or eng_anchor not in eng_positions:\n",
    "            continue\n",
    "        \n",
    "        for akk_pos, eng_pos in position_map.items():\n",
    "            if akk_pos not in akk_positions[logo] or eng_pos not in eng_positions[eng_anchor]:\n",
    "                continue\n",
    "            \n",
    "            akk_words = akk_positions[logo][akk_pos].most_common(10)\n",
    "            eng_words = eng_positions[eng_anchor][eng_pos].most_common(5)\n",
    "            \n",
    "            if not eng_words:\n",
    "                continue\n",
    "            \n",
    "            top_eng = eng_words[0][0]\n",
    "            \n",
    "            for akk_word, akk_count in akk_words:\n",
    "                if akk_count >= 3:\n",
    "                    key = f\"{logo}_{akk_pos}\"\n",
    "                    if akk_word not in vocab:\n",
    "                        vocab[akk_word] = {\n",
    "                            'translation': top_eng,\n",
    "                            'confidence': 0.5,  # Positional has medium confidence\n",
    "                            'count': akk_count,\n",
    "                            'context': key,\n",
    "                            'eng_candidates': [w for w, c in eng_words],\n",
    "                        }\n",
    "    \n",
    "    print(f\"Found {len(vocab)} words from positional analysis\")\n",
    "    return vocab\n",
    "\n",
    "# ============================================================\n",
    "# METHOD 3: HIGH-FREQUENCY UNKNOWN DETECTION\n",
    "# ============================================================\n",
    "\n",
    "def find_high_frequency_unknowns(train_df, existing_vocab):\n",
    "    \"\"\"\n",
    "    Find Akkadian words that appear frequently but aren't in our vocabulary.\n",
    "    These are prime targets for manual review or additional extraction.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Method 3: High-Frequency Unknowns ---\")\n",
    "    \n",
    "    word_counts = Counter()\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        akk_words = tokenize_akk(row['transliteration'])\n",
    "        for w in akk_words:\n",
    "            if w not in AKK_STOP and not is_number(w) and not is_logogram(w):\n",
    "                word_counts[w] += 1\n",
    "    \n",
    "    unknowns = []\n",
    "    for word, count in word_counts.most_common(200):\n",
    "        if word not in existing_vocab and count >= 5:\n",
    "            unknowns.append((word, count))\n",
    "    \n",
    "    print(f\"Found {len(unknowns)} high-frequency unknowns (>=5 occurrences)\")\n",
    "    return unknowns[:50]  # Top 50\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"=\"*60)\n",
    "    print(\"FAST VOCABULARY EXTRACTOR\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load training data only\n",
    "    train = pd.read_csv('/kaggle/input/deep-past-initiative-machine-translation/train.csv')\n",
    "    print(f\"Loaded {len(train)} training sentences\")\n",
    "    \n",
    "    # Method 1: Co-occurrence\n",
    "    cooccur_vocab = extract_cooccurrence(train)\n",
    "    \n",
    "    # Method 2: Positional\n",
    "    positional_vocab = extract_positional(train)\n",
    "    \n",
    "    # Merge vocabularies\n",
    "    merged = {}\n",
    "    for word, data in cooccur_vocab.items():\n",
    "        merged[word] = data\n",
    "    for word, data in positional_vocab.items():\n",
    "        if word not in merged or data.get('confidence', 0) > merged[word].get('confidence', 0):\n",
    "            merged[word] = data\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MERGED VOCABULARY: {len(merged)} words\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Method 3: Find what we're missing\n",
    "    unknowns = find_high_frequency_unknowns(train, merged)\n",
    "    \n",
    "    # ============================================================\n",
    "    # OUTPUT: Formatted for copy-paste into translator\n",
    "    # ============================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HIGH-CONFIDENCE VOCABULARY (>=40%)\")\n",
    "    print(\"Copy this into VOCABULARY dict in mycelial_translator.py\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    high_conf = [(k, v) for k, v in merged.items() if v['confidence'] >= 0.4]\n",
    "    high_conf.sort(key=lambda x: -x[1]['count'])\n",
    "    \n",
    "    print(\"\\n# HIGH CONFIDENCE (>=40%)\")\n",
    "    for akk, data in high_conf[:50]:\n",
    "        eng = data['translation']\n",
    "        eng_escaped = eng.replace(\"'\", \"\\\\'\")  # ← ADD THIS\n",
    "        conf = data['confidence']\n",
    "        count = data['count']\n",
    "        # Guess semantic type based on English word\n",
    "        if eng in ['refined', 'good', 'fine', 'bad', 'washed', 'black', 'white']:\n",
    "            stype = 'quality'\n",
    "        elif eng in ['gave', 'received', 'paid', 'brought', 'sent', 'said', 'returned']:\n",
    "            stype = 'verb'\n",
    "        elif eng in ['silver', 'gold', 'copper', 'tin', 'wool', 'textile']:\n",
    "            stype = 'material'\n",
    "        elif eng in ['brother', 'father', 'mother', 'lord', 'slave']:\n",
    "            stype = 'relation'\n",
    "        else:\n",
    "            stype = 'unknown'\n",
    "        print(f\"    '{akk}': {{'meaning': '{eng_escaped}', 'type': '{stype}', 'confidence': {conf}}},  # {count}x\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MEDIUM-CONFIDENCE VOCABULARY (30-40%)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    med_conf = [(k, v) for k, v in merged.items() if 0.3 <= v['confidence'] < 0.4]\n",
    "    med_conf.sort(key=lambda x: -x[1]['count'])\n",
    "    \n",
    "    print(\"\\n# MEDIUM CONFIDENCE (30-40%) - review before adding\")\n",
    "    for akk, data in med_conf[:30]:\n",
    "        eng = data['translation']\n",
    "        eng_escaped = eng.replace(\"'\", \"\\\\'\")  # ← ADD THIS\n",
    "\n",
    "        conf = data['confidence']\n",
    "        count = data['count']\n",
    "        alts = data.get('alternatives', [])[:3]\n",
    "        alt_str = ', '.join([f\"{w}({c})\" for w, c in alts]) if alts else ''\n",
    "        print(f\"    '{akk}': {{'meaning': '{eng_escaped}', 'type': '{stype}', 'confidence': {conf}}},  # {count}x\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TOP UNKNOWNS (high frequency, not in vocab)\")\n",
    "    print(\"These need manual investigation\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for word, count in unknowns[:20]:\n",
    "        print(f\"    '{word}': ???  # {count}x\")\n",
    "    \n",
    "    # Save JSON for reference\n",
    "    with open('extracted_vocab.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(merged, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\nSaved full vocabulary to extracted_vocab.json\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DONE\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bdf2718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T05:36:50.700960Z",
     "iopub.status.busy": "2026-01-04T05:36:50.700400Z",
     "iopub.status.idle": "2026-01-04T05:36:51.435593Z",
     "shell.execute_reply": "2026-01-04T05:36:51.434511Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.743047,
     "end_time": "2026-01-04T05:36:51.438367",
     "exception": false,
     "start_time": "2026-01-04T05:36:50.695320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Vocabulary (confidence >= 0.4):\n",
      "'šu-ma-bi-a-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'(d)IŠKUR.DÙL-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'zu-ú-lu': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'ší-it-ar-ša-a': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'eṭ-ra-šu': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'ra-da-x': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'tù-ša-ak-ší-dí': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'a-ra-ší-a-ku-um': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'ta-ta-wu-ni': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'a-ṭá-ra-da-ku-nu-tí': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'…-mu': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'…-nam': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'ta-ṭá-ba-am': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'sà-ra-tí-ni-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'pu-ru-sà': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'a-ki-ri': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'DU-ú': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'NÍG-KA-sé': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'ta-sí-a-ni': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'iq-bi₄-a-ku-ni': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'šé-sí-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'ni-dí-šu-nu-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'ṣú-ba-tí-šu-nu': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'mu-ša-lam': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'a-la-qé-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'xxxx-tim': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'e-lá-i-kà': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'x-li-ší-a-ta': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'ší-it-re': {'meaning': '...', 'type': 'unknown', 'confidence': 1.0},\n",
      "'nim-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 0.83},\n",
      "'e-ṭá-ar': {'meaning': 'as', 'type': 'unknown', 'confidence': 0.67},\n",
      "'té-ra-ba-ni': {'meaning': 'as', 'type': 'unknown', 'confidence': 0.67},\n",
      "'…-at-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'([ANCHOR])ku-ta-nu-kà': {'meaning': 'textiles', 'type': 'unknown', 'confidence': 0.67},\n",
      "'i-dí-ku-bu-ma': {'meaning': 'you', 'type': 'unknown', 'confidence': 0.67},\n",
      "'a-ni-a-tím': {'meaning': 'by', 'type': 'unknown', 'confidence': 0.67},\n",
      "'i-šé-ra-ku-nu-tí-ni': {'meaning': 'or', 'type': 'unknown', 'confidence': 0.67},\n",
      "'95': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'tù-lá-mì-in': {'meaning': 'i', 'type': 'unknown', 'confidence': 0.67},\n",
      "'a-šu-um-ke': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'um-mì-im': {'meaning': 'there', 'type': 'unknown', 'confidence': 0.67},\n",
      "'mu-ur-ṣí-im': {'meaning': 'no', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ta-kà-ší-dí-ni': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ú-ta-ru-nim': {'meaning': 'your', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ku-sí-lá-nim': {'meaning': 'before', 'type': 'unknown', 'confidence': 0.67},\n",
      "'tap-pá-e-šu': {'meaning': 'as', 'type': 'unknown', 'confidence': 0.67},\n",
      "'za-ku-ú-um': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'tù-pá-ra-dá-šu': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'x-lá-ni-ší-na': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ú-kà-lu-nim': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'me-ra-kà': {'meaning': 'minas', 'type': 'unknown', 'confidence': 0.67},\n",
      "'xx-na-ša': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'at-lá+lá-x': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'tù-kà-lá-nim': {'meaning': 'as', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ú-ṣur-a-num': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ḫa-al-ki-a-šu': {'meaning': 'by', 'type': 'unknown', 'confidence': 0.67},\n",
      "'li-it-ru-nim': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ša-ak-šu-dí': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ša-ak-ší-dí': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'li-bi₄-im': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'la-ší-na-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ki-ni-…': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ḫa-ma-li-a': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'na-ší-ma': {'meaning': 'as', 'type': 'unknown', 'confidence': 0.67},\n",
      "'tù-ša-as-ḫa-ra-ni': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'x-xx': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'wa-li-wa-li': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'me-nu-ni-a-nam': {'meaning': 'per', 'type': 'unknown', 'confidence': 0.67},\n",
      "'IŠTAR.DINGIR-šu': {'meaning': 'per', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ip-ṭí-re': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ma-x-im': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'tù-la-ma-an': {'meaning': 'i', 'type': 'unknown', 'confidence': 0.67},\n",
      "'dí-na-nim': {'meaning': 'from', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ḫi-…': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'x-kà-ma': {'meaning': 'as', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ša-lá-áš-tù-ma': {'meaning': 'as', 'type': 'unknown', 'confidence': 0.67},\n",
      "'i-šé-e-šu': {'meaning': 'mina', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ga-…': {'meaning': 'by', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ku-lu-ú': {'meaning': '[ANCHOR],', 'type': 'unknown', 'confidence': 0.67},\n",
      "'i-a-tí-i': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ḫa-li-iq': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'i-ta-mu-ú': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'x-a-na': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'li-iš-qú-lam': {'meaning': 'him', 'type': 'unknown', 'confidence': 0.67},\n",
      "'tù-kà-li-mì-ni': {'meaning': 'tablet', 'type': 'unknown', 'confidence': 0.67},\n",
      "'šé-ru-dí-im': {'meaning': 'you', 'type': 'unknown', 'confidence': 0.67},\n",
      "'i-xxx': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'at-wu-ú-um': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'A.KI-il₅-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ta-áp-…': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'i-pé-té': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'a-li-ma': {'meaning': 'your', 'type': 'unknown', 'confidence': 0.67},\n",
      "'x-AG': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'kà-bi-sú': {'meaning': 'father', 'type': 'unknown', 'confidence': 0.67},\n",
      "'pá-tí-at-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'šu-ga-ri-a-am': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'bu-…-kum': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ú-šé-ri-bu-ni-a-tí-ma': {'meaning': 'us', 'type': 'unknown', 'confidence': 0.67},\n",
      "'da-áš-i-šu': {'meaning': 'as', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ku-ra-xxx': {'meaning': 'pay', 'type': 'unknown', 'confidence': 0.67},\n",
      "'li-dí-na-ki-NU-tí': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ma-sà-a-am': {'meaning': '1', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ir-i-bu-um': {'meaning': 'brother', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ta-ta-mar': {'meaning': 'you', 'type': 'unknown', 'confidence': 0.67},\n",
      "'na-aš-pé-er-tum': {'meaning': 'about', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ni-ḫi-bi₄-il₅': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ta-ad-nu-ma': {'meaning': 'was', 'type': 'unknown', 'confidence': 0.67},\n",
      "'šu-qú-lam-ma': {'meaning': 'as', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ḫi-im-ṭá-tim': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'qá-tí-ki': {'meaning': 'urgent,', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ta-mì-i-ma': {'meaning': 'as', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ṣa-ba-tim': {'meaning': 'you', 'type': 'unknown', 'confidence': 0.67},\n",
      "'be-lá-num-ma': {'meaning': 'bēlānum', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ú-ku-ul-ti-šu-nu': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'x-šu-nu': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'na-ab-ri-tim': {'meaning': 'its', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ga-am-ra-am': {'meaning': 'shekels', 'type': 'unknown', 'confidence': 0.67},\n",
      "'e-ri-mu-ša': {'meaning': 'from', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ú-ba-ar-za-a': {'meaning': 'by', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ú-a-na-me-a': {'meaning': 'by', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ḫa-šu-ta-a-li-i': {'meaning': 'by', 'type': 'unknown', 'confidence': 0.67},\n",
      "'a-am': {'meaning': 'you', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ša-ni-iš': {'meaning': 'eponym', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ki-šar-ší-im': {'meaning': 'were', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ú-šé-ba-lá-ku-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'xxxxxx-kà': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'x-mu': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'iz-me-ru-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'80.83333': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'il₅-pu-tù-ni-a-tí-ma': {'meaning': 'as', 'type': 'unknown', 'confidence': 0.67},\n",
      "'19.5': {'meaning': 'by', 'type': 'unknown', 'confidence': 0.67},\n",
      "'nu-ḫu-um': {'meaning': '1', 'type': 'unknown', 'confidence': 0.67},\n",
      "'i-sà-na-li-ú-ni-ma': {'meaning': 'me,', 'type': 'unknown', 'confidence': 0.67},\n",
      "'a-ṣé-ri-šu-nu': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ḫa-tí-kà-it-ra': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'a-šur-mu-ta-píl': {'meaning': 'him', 'type': 'unknown', 'confidence': 0.67},\n",
      "'i-du-mu-nim': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'tù-šé-ba-lá-ni-ni': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'sà-aḫ-ra-ku': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'DÍ-RI-ú': {'meaning': 'colony', 'type': 'unknown', 'confidence': 0.67},\n",
      "'ga-am-ri-kà': {'meaning': '...', 'type': 'unknown', 'confidence': 0.67},\n",
      "'x-bi-šu': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'ú-šé-bi-lam-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'šál-mu': {'meaning': 'your', 'type': 'unknown', 'confidence': 0.5},\n",
      "'…-tim': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'it-ba-al-bu-lu': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'ṣú-ba-sà-a': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'wa-ar-ki-a-tim': {'meaning': 'per', 'type': 'unknown', 'confidence': 0.5},\n",
      "'wa-ar-ki-a': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'qá-bi₄-a-tí': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'ni-a-tim': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'ta-ki-tám': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'šu-ra-am': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'…-bu': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'a-am-tám': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'a-na-ru-uq': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'ma-ma': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'na-…': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'ší-mì-šu-nu': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'en-nam-(d)IM': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'ša-kà-ki-iš': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'nu-ší-ib-ma': {'meaning': 'mina', 'type': 'unknown', 'confidence': 0.5},\n",
      "'ma-ri-iṣ': {'meaning': '...', 'type': 'unknown', 'confidence': 0.5},\n",
      "'lu-mu-un': {'meaning': '...', 'type': 'unknown', 'confidence': 0.44},\n",
      "'wa-ba-ra-tim': {'meaning': 'until', 'type': 'unknown', 'confidence': 0.4},\n",
      "\n",
      "Full extracted vocab (>=0.3) saved to /kaggle/working/extracted_vocab.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION & NEUTRALIZATION MAP\n",
    "# ============================================================\n",
    "LOGO_TO_ENGLISH = {\n",
    "    'KÙ.BABBAR': 'silver', 'KÙ.GI': 'gold', 'URUDU': 'copper',\n",
    "    'AN.NA': 'tin', 'GÍN': 'shekel', 'MA.NA': 'mina',\n",
    "    'DUMU': 'son', 'KIŠIB': 'seal', 'É': 'house', 'ANŠE': 'donkey',\n",
    "    'TÚG': 'textile', 'ITU': 'month', 'IGI': 'witness',\n",
    "}\n",
    "NAME_ANCHORS = {'DUMU', 'KIŠIB', 'PÀD'}\n",
    "AKK_STOP = {'ša', 'a-na', 'ù', 'ú', 'i-na', 'x', 'xx', '…'}\n",
    "ENG_STOP = {'the', 'a', 'an', 'of', 'and', 'to', 'in', 'for', 'is', 'his', 'her', 'my'}\n",
    "\n",
    "# ============================================================\n",
    "# IMPROVED HELPERS\n",
    "# ============================================================\n",
    "def neutralize_line(akk_text, eng_text):\n",
    "    clean_akk = akk_text\n",
    "    clean_eng = eng_text.lower()\n",
    "    \n",
    "    for logo, eng in LOGO_TO_ENGLISH.items():\n",
    "        if logo in clean_akk and eng in clean_eng:\n",
    "            clean_akk = clean_akk.replace(logo, \"[ANCHOR]\")\n",
    "            # FIX 1: Regex escaping to handle periods/parens in English\n",
    "            clean_eng = re.sub(rf'\\b{re.escape(eng)}\\b', \"[ANCHOR]\", clean_eng)\n",
    "            \n",
    "    return clean_akk, clean_eng\n",
    "\n",
    "def get_name_mask(train_df):\n",
    "    \"\"\"\n",
    "    FIX 2: Captures two tokens after anchors to handle multi-word\n",
    "    patronyms (e.g., 'DUMU I-din-A-šur').\n",
    "    \"\"\"\n",
    "    names = set()\n",
    "    for _, row in train_df.iterrows():\n",
    "        tokens = row['transliteration'].split()\n",
    "        for i, t in enumerate(tokens):\n",
    "            if t in NAME_ANCHORS:\n",
    "                if i + 1 < len(tokens): names.add(tokens[i+1])\n",
    "                if i + 2 < len(tokens): names.add(tokens[i+2])\n",
    "    return names\n",
    "\n",
    "# ============================================================\n",
    "# DISTRIBUTIONAL TYPE CLASSIFICATION (Honeycomb Methodology)\n",
    "# ============================================================\n",
    "def classify_by_distribution(word, meaning, context_positions):\n",
    "    \"\"\"\n",
    "    Uses the Chaveste methodology: Words aren't defined by surface form,\n",
    "    but by their 'structural neighborhood.'\n",
    "    \"\"\"\n",
    "    # If a word consistently follows a number -> it's likely a UNIT\n",
    "    if any('pre' in pos and 'number' in pos for pos in context_positions):\n",
    "        return 'unit'\n",
    "    # If it appears at the end of a sentence following a list -> likely a VERB\n",
    "    if meaning in ['gave', 'paid', 'received', 'sent', 'took']:\n",
    "        return 'verb'\n",
    "    # Defaulting to the English semantic mapping for now\n",
    "    return 'unknown'\n",
    "\n",
    "# ============================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================\n",
    "if __name__ == '__main__':\n",
    "    train = pd.read_csv('/kaggle/input/deep-past-initiative-machine-translation/train.csv')\n",
    "    name_mask = get_name_mask(train)\n",
    "    \n",
    "    # Extraction logic\n",
    "    vocab_candidates = defaultdict(Counter)\n",
    "    context_pos = defaultdict(list)  # For type classification, stub for now\n",
    "    \n",
    "    for _, row in train.iterrows():\n",
    "        akk_text = row['transliteration']\n",
    "        eng_text = row['translation']\n",
    "        clean_akk, clean_eng = neutralize_line(akk_text, eng_text)\n",
    "        akk_tokens = [t for t in re.split(r'\\s+', clean_akk) if t and t not in AKK_STOP and t != '[ANCHOR]']\n",
    "        eng_tokens = [t for t in re.split(r'\\s+', clean_eng) if t and t not in ENG_STOP and t != '[ANCHOR]']\n",
    "        \n",
    "        # Assume rough alignment by position, use ±1 window for co-occurrence\n",
    "        min_len = min(len(akk_tokens), len(eng_tokens))\n",
    "        for i in range(min_len):\n",
    "            akk_word = akk_tokens[i]\n",
    "            if akk_word in name_mask or akk_word.isupper():  # Skip names and potential logograms\n",
    "                continue\n",
    "            for j in range(max(0, i-1), min(len(eng_tokens), i+2)):\n",
    "                eng_word = eng_tokens[j]\n",
    "                vocab_candidates[akk_word][eng_word] += 1\n",
    "                # Stub for context (expand as needed): track relative positions\n",
    "                if j < i: context_pos[akk_word].append('pre')\n",
    "                if eng_word.isdigit(): context_pos[akk_word].append('number')\n",
    "    \n",
    "    # Compute vocab with confidence\n",
    "    extracted_vocab = {}\n",
    "    for akk_word, eng_counts in vocab_candidates.items():\n",
    "        total = sum(eng_counts.values())\n",
    "        if total < 3: continue  # Min occurrences to reduce noise\n",
    "        top_eng, top_count = eng_counts.most_common(1)[0]\n",
    "        confidence = top_count / total\n",
    "        if confidence >= 0.3:  # Keep for JSON\n",
    "            word_type = classify_by_distribution(akk_word, top_eng, context_pos.get(akk_word, []))\n",
    "            extracted_vocab[akk_word] = {\n",
    "                'meaning': top_eng,\n",
    "                'type': word_type,\n",
    "                'confidence': round(confidence, 2)\n",
    "            }\n",
    "    \n",
    "    # Display >= 0.4\n",
    "    print(\"Extracted Vocabulary (confidence >= 0.4):\")\n",
    "    for word, data in sorted(extracted_vocab.items(), key=lambda x: x[1]['confidence'], reverse=True):\n",
    "        if data['confidence'] >= 0.4:\n",
    "            print(f\"'{word}': {{'meaning': '{data['meaning']}', 'type': '{data['type']}', 'confidence': {data['confidence']}}},\")\n",
    "    \n",
    "    # Save all >=0.3 to JSON\n",
    "    with open('/kaggle/working/extracted_vocab.json', 'w') as f:\n",
    "        json.dump(extracted_vocab, f, indent=4)\n",
    "    print(\"\\nFull extracted vocab (>=0.3) saved to /kaggle/working/extracted_vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f833639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T05:36:51.447430Z",
     "iopub.status.busy": "2026-01-04T05:36:51.447096Z",
     "iopub.status.idle": "2026-01-04T05:36:52.137015Z",
     "shell.execute_reply": "2026-01-04T05:36:52.136007Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.6974,
     "end_time": "2026-01-04T05:36:52.139625",
     "exception": false,
     "start_time": "2026-01-04T05:36:51.442225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VOCAB EXTRACTOR v5 - NAME BLACKLISTING\n",
      "============================================================\n",
      "Loaded 1561 training sentences\n",
      "\n",
      "--- Pass 1: Identifying names ---\n",
      "Found 1116 unique names (blacklisted from vocabulary)\n",
      "\n",
      "Sample names (first 20):\n",
      "  ma-sà-a-a\n",
      "  dan-a-a\n",
      "  a-gu-a\n",
      "  ku-ta-a\n",
      "  a-šùr-bé-el-a-wa-tim\n",
      "  la-qé-pì-im\n",
      "  šu-(d)EN.LÍL\n",
      "  mu-mu-lá-nim\n",
      "  ša-ar-ni-ga-a-šu\n",
      "  la-li-im\n",
      "  a-šùr-be-el-a-wa-tim\n",
      "  a-nu-li\n",
      "  a-šur\n",
      "  en-nam-(d)IŠKUR\n",
      "  en-num-a-šur\n",
      "  da-da-nim\n",
      "  a-šur-ṣú-lu-li\n",
      "  ku-ṣí-im\n",
      "  i-di-a-bi₄-im\n",
      "  in-ba-a-šùr\n",
      "\n",
      "--- Pass 2: Extracting vocabulary ---\n",
      "Extracted 210 vocabulary words\n",
      "\n",
      "============================================================\n",
      "VOCABULARY BY TYPE (copy to mycelial_translator.py)\n",
      "============================================================\n",
      "\n",
      "# === VERB (13 words) ===\n",
      "    'šé-bi₄-lam': {'meaning': 'send', 'type': 'verb', 'confidence': 0.37},  # 16x | alts: ['silver', 'good']\n",
      "    'ša-bu-ú': {'meaning': 'paid', 'type': 'verb', 'confidence': 0.33},  # 8x | alts: ['tariff', 'transport']\n",
      "    'iḫ-da': {'meaning': 'take', 'type': 'verb', 'confidence': 0.44},  # 7x | alts: ['care', 'brothers']\n",
      "    'a-dí-na-ku-ni': {'meaning': 'gave', 'type': 'verb', 'confidence': 0.33},  # 4x | alts: ['send', 'silver']\n",
      "    'ša-áš-qí-il₅': {'meaning': 'paid', 'type': 'verb', 'confidence': 0.57},  # 4x | alts: ['interest', 'one']\n",
      "    'lu-ub-lu-nim': {'meaning': 'bring', 'type': 'verb', 'confidence': 0.31},  # 4x | alts: ['also', 'may']\n",
      "    'ṭur₄-da-ni-šu': {'meaning': 'send', 'type': 'verb', 'confidence': 0.5},  # 3x | alts: ['give', 'sacks']\n",
      "    'ṭup-pá-áš-nu': {'meaning': 'give', 'type': 'verb', 'confidence': 0.38},  # 3x | alts: ['similar', 'amount']\n",
      "    'ḫu-bu-li-šu': {'meaning': 'paid', 'type': 'verb', 'confidence': 0.33},  # 3x | alts: ['wah', 'ana']\n",
      "    'ú-šé-ba-lá-kum': {'meaning': 'send', 'type': 'verb', 'confidence': 0.33},  # 3x | alts: ['price', 'garments']\n",
      "    'ša-mu-ḫa': {'meaning': 'gave', 'type': 'verb', 'confidence': 0.75},  # 3x | alts: ['station', 'amuha']\n",
      "    'i-dí-ni-ma': {'meaning': 'gave', 'type': 'verb', 'confidence': 0.3},  # 3x | alts: ['these', 'proceedings']\n",
      "    'a-lá-qé-ma': {'meaning': 'take', 'type': 'verb', 'confidence': 0.6},  # 3x | alts: ['mina', 'again']\n",
      "\n",
      "# === QUALITY (1 words) ===\n",
      "    'ša-bu-ra-am': {'meaning': 'washed', 'type': 'quality', 'confidence': 0.38},  # 3x | alts: ['talents', 'broken']\n",
      "\n",
      "# === RELATION (4 words) ===\n",
      "    'a-bu-kà': {'meaning': 'father', 'type': 'relation', 'confidence': 0.31},  # 4x | alts: ['anna', 'answered']\n",
      "    'um-mì-ki': {'meaning': 'mother', 'type': 'relation', 'confidence': 0.36},  # 4x | alts: ['shekels', 'silver']\n",
      "    'be-li': {'meaning': 'lord', 'type': 'relation', 'confidence': 0.38},  # 3x | alts: ['father', 'witnesses']\n",
      "    'a-ma-tim': {'meaning': 'slave', 'type': 'relation', 'confidence': 0.38},  # 3x | alts: ['girls', 'concerning']\n",
      "\n",
      "# === PLACE (5 words) ===\n",
      "    'ni-lik': {'meaning': 'city', 'type': 'place', 'confidence': 0.31},  # 4x | alts: ['ahum', 'shows']\n",
      "    'šu-nu-tí': {'meaning': 'house', 'type': 'place', 'confidence': 0.38},  # 3x | alts: ['pay', 'orders']\n",
      "    'ú-ma-lá': {'meaning': 'city', 'type': 'place', 'confidence': 0.33},  # 3x | alts: ['wages', 'shall']\n",
      "    'ší-ma-at': {'meaning': 'city', 'type': 'place', 'confidence': 0.43},  # 3x | alts: ['lik', 'lying']\n",
      "    'É-té': {'meaning': 'house', 'type': 'place', 'confidence': 1.0},  # 3x | alts: ['become']\n",
      "\n",
      "# === DOCUMENT (5 words) ===\n",
      "    'ḫa-ar-ma-am': {'meaning': 'tablet', 'type': 'document', 'confidence': 0.32},  # 10x | alts: ['certified', 'silver']\n",
      "    'i-dí-in-ma': {'meaning': 'verdict', 'type': 'document', 'confidence': 0.41},  # 9x | alts: ['passed', 'stating']\n",
      "    'ta-ša-me-ú': {'meaning': 'letter', 'type': 'document', 'confidence': 0.3},  # 6x | alts: ['must', 'set']\n",
      "    'ḫa-ru-mu-tum': {'meaning': 'certified', 'type': 'document', 'confidence': 0.75},  # 3x | alts: ['tablets', 'silver']\n",
      "    'al-pu-ut': {'meaning': 'tablet', 'type': 'document', 'confidence': 0.38},  # 3x | alts: ['city', 'brother']\n",
      "\n",
      "# === TIME (7 words) ===\n",
      "    'ḫu-bu-ur': {'meaning': 'month', 'type': 'time', 'confidence': 0.46},  # 6x | alts: ['hubur', 'eponymy']\n",
      "    'té-i-na-tim': {'meaning': 'eponymy', 'type': 'time', 'confidence': 0.5},  # 5x | alts: ['tum', 'month']\n",
      "    'ḫa-mu-uš-tum': {'meaning': 'week', 'type': 'time', 'confidence': 1.0},  # 4x | alts: ['eponymy', 'tawiniya']\n",
      "    'ITU.1.KAM-im': {'meaning': 'month', 'type': 'time', 'confidence': 0.38},  # 3x | alts: ['rate', 'per']\n",
      "    'áb-ša-ra-ni': {'meaning': 'eponymy', 'type': 'time', 'confidence': 0.3},  # 3x | alts: ['month', 'kuliya']\n",
      "    'qá-ra-a-tim': {'meaning': 'eponymy', 'type': 'time', 'confidence': 0.6},  # 3x | alts: ['give', 'witnessed']\n",
      "    'ṣí-ip-im': {'meaning': 'month', 'type': 'time', 'confidence': 0.5},  # 3x | alts: ['vii', 'per']\n",
      "\n",
      "# === MATERIAL (25 words) ===\n",
      "    '(TÚG)ku-ta-nu': {'meaning': 'textiles', 'type': 'material', 'confidence': 0.31},  # 9x | alts: ['talents', 'mina']\n",
      "    '(TÚG)šu-ru-tum': {'meaning': 'textiles', 'type': 'material', 'confidence': 0.47},  # 7x | alts: ['dark', 'minas']\n",
      "    'na-áš-a-ku-um': {'meaning': 'silver', 'type': 'material', 'confidence': 0.38},  # 6x | alts: ['under', 'brother']\n",
      "    'li-wi-tim': {'meaning': 'textiles', 'type': 'material', 'confidence': 0.35},  # 6x | alts: ['used', 'dark']\n",
      "    'qá-qá-ad': {'meaning': 'silver', 'type': 'material', 'confidence': 0.3},  # 6x | alts: ['jointly', 'weeks']\n",
      "    'li-il₅-qé': {'meaning': 'silver', 'type': 'material', 'confidence': 0.4},  # 4x | alts: ['yourselves', 'should']\n",
      "    'ḫu-sà-ri-im': {'meaning': 'lapis', 'type': 'material', 'confidence': 0.31},  # 4x | alts: ['lazuli', 'price']\n",
      "    'xxxxxxx': {'meaning': 'silver', 'type': 'material', 'confidence': 0.33},  # 4x | alts: ['sil', 'ver']\n",
      "    'lá-mu-nam': {'meaning': 'copper', 'type': 'material', 'confidence': 0.5},  # 4x | alts: ['good', 'bad']\n",
      "    'ad-ma-ku': {'meaning': 'textiles', 'type': 'material', 'confidence': 0.36},  # 4x | alts: ['king', 'went']\n",
      "    'tí-me-el-ki-a': {'meaning': 'silver', 'type': 'material', 'confidence': 0.4},  # 4x | alts: ['taken', 'ali']\n",
      "    'GÌN': {'meaning': 'silver', 'type': 'material', 'confidence': 0.6},  # 3x | alts: ['ennanatum', 'funds']\n",
      "    'ṣú-ba-tí-kà': {'meaning': 'textiles', 'type': 'material', 'confidence': 0.33},  # 3x | alts: ['tin', 'fine']\n",
      "    'be-a-lim': {'meaning': 'silver', 'type': 'material', 'confidence': 0.33},  # 3x | alts: ['refined', 'mina']\n",
      "    'URUDU-i-kà': {'meaning': 'copper', 'type': 'material', 'confidence': 0.33},  # 3x | alts: ['talents', 'minas']\n",
      "    'ra-mì-ni-kà': {'meaning': 'silver', 'type': 'material', 'confidence': 0.5},  # 3x | alts: ['give', 'provisions']\n",
      "    'ra-qá-tám': {'meaning': 'textile', 'type': 'material', 'confidence': 0.3},  # 3x | alts: ['put', 'true']\n",
      "    'kà-ṣa-ri': {'meaning': 'textiles', 'type': 'material', 'confidence': 0.38},  # 3x | alts: ['further', 'belonging']\n",
      "    'il₅-té-qé': {'meaning': 'silver', 'type': 'material', 'confidence': 0.75},  # 3x | alts: ['own', \"iliya's\"]\n",
      "    'ṭup-pí-šu-nu': {'meaning': 'silver', 'type': 'material', 'confidence': 0.6},  # 3x | alts: ['pay', 'attention']\n",
      "    'li-dí-na-ku-nu-tí-ma': {'meaning': 'silver', 'type': 'material', 'confidence': 0.43},  # 3x | alts: ['tablet', 'give']\n",
      "    'šu-ru-tim': {'meaning': 'textiles', 'type': 'material', 'confidence': 0.38},  # 3x | alts: ['shekels', 'tin']\n",
      "    'ta-ša-qá-lam': {'meaning': 'silver', 'type': 'material', 'confidence': 0.5},  # 3x | alts: ['pay', 'representatives']\n",
      "    'lu-bu-šu': {'meaning': 'silver', 'type': 'material', 'confidence': 0.43},  # 3x | alts: ['clothing', 'allowance']\n",
      "    'KÙ.BABBAR.KI': {'meaning': 'silver', 'type': 'material', 'confidence': 1.0},  # 3x | alts: ['owed', 'shekels']\n",
      "\n",
      "# === UNIT (5 words) ===\n",
      "    'ší-ku-um': {'meaning': 'minas', 'type': 'unit', 'confidence': 0.44},  # 4x | alts: ['copper', 'ikku']\n",
      "    'lá-mu-num': {'meaning': 'minas', 'type': 'unit', 'confidence': 0.33},  # 3x | alts: ['talents', 'copper']\n",
      "    'ku-ta-nim': {'meaning': 'minas', 'type': 'unit', 'confidence': 0.33},  # 3x | alts: ['textile', 'talents']\n",
      "    'ŠÀ': {'meaning': 'shekels', 'type': 'unit', 'confidence': 0.38},  # 3x | alts: ['3333', 'silver']\n",
      "    'KÙ.BABBAR-šu-nu': {'meaning': 'shekels', 'type': 'unit', 'confidence': 1.0},  # 3x | alts: ['became', 'harness']\n",
      "\n",
      "# === UNKNOWN (145 words) ===\n",
      "    'ú-ṣa-áb': {'meaning': 'per', 'type': 'unknown', 'confidence': 0.31},  # 32x | alts: ['month', 'mina']\n",
      "    'a-pu-tum': {'meaning': 'urgent', 'type': 'unknown', 'confidence': 0.39},  # 29x | alts: ['very', 'send']\n",
      "    'i-dí-ni-a-tí-ma': {'meaning': 'these', 'type': 'unknown', 'confidence': 0.36},  # 25x | alts: ['proceedings', 'gave']\n",
      "    'ša-lim-a-šùr-ma': {'meaning': 'alim', 'type': 'unknown', 'confidence': 0.5},  # 21x | alts: ['lum', 'slave']\n",
      "    'ší-bu-tí-ni': {'meaning': 'before', 'type': 'unknown', 'confidence': 0.3},  # 20x | alts: ['testimony', 'gave']\n",
      "    'i-dí-a-bu-um': {'meaning': 'abum', 'type': 'unknown', 'confidence': 0.48},  # 16x | alts: ['iddin', 'minas']\n",
      "    'ší-a-ma-tim': {'meaning': 'purchases', 'type': 'unknown', 'confidence': 0.3},  # 13x | alts: ['making', 'tar']\n",
      "    'a-mur-IŠTAR-ma': {'meaning': 'tar', 'type': 'unknown', 'confidence': 0.45},  # 13x | alts: ['amur', 'thus']\n",
      "    'NINDA': {'meaning': 'breads', 'type': 'unknown', 'confidence': 0.36},  # 13x | alts: ['100', 'interest']\n",
      "    'mì-šu': {'meaning': 'why', 'type': 'unknown', 'confidence': 0.34},  # 12x | alts: ['tin', 'ahum']\n",
      "    'ŠE-am': {'meaning': 'barley', 'type': 'unknown', 'confidence': 0.37},  # 11x | alts: ['sacks', 'wheat']\n",
      "    'ki-ru-um': {'meaning': 'jar', 'type': 'unknown', 'confidence': 0.65},  # 11x | alts: ['ahuni', 'iddin']\n",
      "    'e-lá-ma-ma': {'meaning': 'elamma', 'type': 'unknown', 'confidence': 0.71},  # 10x | alts: ['thus', 'say']\n",
      "    'ma-ma-ḫi-ir-ma': {'meaning': 'man', 'type': 'unknown', 'confidence': 0.82},  # 9x | alts: ['mahir', 'interior']\n",
      "    'tap-pá-i-ni': {'meaning': 'absent', 'type': 'unknown', 'confidence': 0.5},  # 9x | alts: ['partner', 'buzi']\n",
      "    'ša-lim-a-šur-ma': {'meaning': 'alim', 'type': 'unknown', 'confidence': 0.4},  # 8x | alts: ['sworn', 'detain']\n",
      "    'a-lá-ḫu-um-ma': {'meaning': 'ali', 'type': 'unknown', 'confidence': 0.31},  # 8x | alts: ['ahum', 'answered']\n",
      "    'ú-ší-na-lam': {'meaning': 'inalam's', 'type': 'unknown', 'confidence': 0.32},  # 8x | alts: ['wool', 'silver']\n",
      "    'ki-ra-am': {'meaning': 'jar', 'type': 'unknown', 'confidence': 0.67},  # 8x | alts: ['meat', 'galgaliya']\n",
      "    'en-nam-a-šur-ma': {'meaning': 'ennam', 'type': 'unknown', 'confidence': 0.62},  # 8x | alts: ['silver', 'minas']\n",
      "    'ṭup-pu-ú': {'meaning': 'tablets', 'type': 'unknown', 'confidence': 0.47},  # 7x | alts: ['silver', 'should']\n",
      "    'i-sí-ú-ma': {'meaning': 'accounts', 'type': 'unknown', 'confidence': 0.64},  # 7x | alts: ['settled', 'claimed']\n",
      "    'ša-am-ší': {'meaning': 'very', 'type': 'unknown', 'confidence': 0.33},  # 6x | alts: ['day', 'hear']\n",
      "    'ku-bu-ur-na-at': {'meaning': 'kuburnat', 'type': 'unknown', 'confidence': 0.35},  # 6x | alts: ['here', 'obtained']\n",
      "    'za-al-pá': {'meaning': 'zalpa', 'type': 'unknown', 'confidence': 0.46},  # 6x | alts: ['scarfs', 'ennam']\n",
      "\n",
      "============================================================\n",
      "NAMES BLACKLIST (1116 total)\n",
      "These are kept as transliteration, not translated\n",
      "============================================================\n",
      "\n",
      "First 50 names:\n",
      "  (d)AB-ba-ni\n",
      "  (d)EN.LÍL-ba-ni\n",
      "  (d)EN.ZU-na-da\n",
      "  (d)I-ba-ni\n",
      "  (d)IM-ba-ni\n",
      "  (d)IM-pì-lá-aḫ\n",
      "  (d)IM-re-x\n",
      "  (d)IM.GAL\n",
      "  (d)IM.SIG₅\n",
      "  (d)IŠKUR-ba-ni\n",
      "  (d)IŠKUR-pí-la-aḫ\n",
      "  (d)IŠKUR.ILLAT\n",
      "  (d)IŠTAR-pí-lá-aḫ\n",
      "  (d)MAR.TU-ba-ni\n",
      "  (d)MUŠ-mu-ta-bi-il₅\n",
      "  (d)MUŠ-mu-ta-bíl\n",
      "  (d)NIN.ŠUBUR-ba-ni\n",
      "  (d)UTU-a-bi\n",
      "  (d)UTU-ba-ni\n",
      "  (d)UTU-na-ṣí-ir\n",
      "  (d)UTU-ṣú-lu-li\n",
      "  (d)UTU.DU₁₀\n",
      "  (d)a-šur-(d)UTU-ši\n",
      "  (d)li-i-ba-a\n",
      "  A-ki\n",
      "  A-ta-a\n",
      "  AḪ.ME-ša-sú-in\n",
      "  DINGIR-ba-ni\n",
      "  DINGIR-ku-ru-ub\n",
      "  DINGIR-kur-ub\n",
      "  DINGIR-ma-a-šur\n",
      "  DINGIR-mu-ta-bi₄-il₅\n",
      "  DINGIR-na-da\n",
      "  DINGIR-pì-la-aḫ\n",
      "  DINGIR-pì-lá-aḫ\n",
      "  DINGIR-tap-pá-a\n",
      "  DINGIR-x\n",
      "  DINGIR.ILLAT\n",
      "  DINGIR.SIPA\n",
      "  DIRI-e-im\n",
      "  DIRI-im\n",
      "  DUG-ṣí-li-a-šur\n",
      "  DUMU\n",
      "  DU₁₀-a-šur\n",
      "  DU₁₀-a-ḫi\n",
      "  DU₁₀-a-ḫi-e\n",
      "  DU₁₀-pí-a-šùr\n",
      "  DU₁₀-ì-lí\n",
      "  DU₁₀-ṣí-li-a-šur\n",
      "  DU₁₀-ṣí-lá-a-šur\n",
      "\n",
      "============================================================\n",
      "DONE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VOCABULARY EXTRACTOR v5 - NAME BLACKLISTING\n",
    "============================================\n",
    "Key fix: Words immediately after DUMU, KIŠIB, IGI are NAMES.\n",
    "Pass 1: Identify all names\n",
    "Pass 2: Extract vocabulary, excluding names\n",
    "\n",
    "This prevents names from being incorrectly mapped to 'son', 'seal', etc.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "LOGO_TO_ENGLISH = {\n",
    "    'KÙ.BABBAR': 'silver', 'KÙ.GI': 'gold', 'URUDU': 'copper',\n",
    "    'AN.NA': 'tin', 'GÍN': 'shekel', 'GÍN.TA': 'shekel',\n",
    "    'MA.NA': 'mina', 'GÚ': 'talent', 'DUMU': 'son',\n",
    "    'DUMU.MUNUS': 'daughter', 'DAM': 'wife', 'DAM.GÀR': 'merchant',\n",
    "    'KIŠIB': 'seal', 'É': 'house', 'ANŠE': 'donkey',\n",
    "    'TÚG': 'textile', 'TÚG.ḪI.A': 'textiles', 'UDU': 'sheep',\n",
    "    'SÍG': 'wool', 'ITU': 'month', 'IGI': 'witness',\n",
    "    'SIG₅': 'fine', 'GÍR': 'dagger', 'ŠU.NÍGIN': 'total',\n",
    "}\n",
    "\n",
    "# Markers that indicate next word is a NAME\n",
    "NAME_MARKERS = {'DUMU', 'KIŠIB', 'IGI', 'DAM', 'DUMU.MUNUS'}\n",
    "\n",
    "AKK_STOP = {'ša', 'a-na', 'ù', 'ú', 'i-na', 'x', 'xx', 'xxx', '…', '-', '', 'ma'}\n",
    "ENG_STOP = {\n",
    "    'the', 'a', 'an', 'of', 'and', 'to', 'in', 'for', 'is', 'are',\n",
    "    'was', 'were', 'be', 'have', 'has', 'had', 'he', 'she', 'it',\n",
    "    'they', 'we', 'i', 'you', 'my', 'your', 'his', 'her', 'its',\n",
    "    'their', 'our', 'from', 'with', 'by', 'at', 'on', 'as', 'or',\n",
    "    'if', 'but', 'not', 'no', 'that', 'this', 'which', 'who',\n",
    "    'him', 'me', 'us', 'them', 'so', 'then', 'when', 'will',\n",
    "    'said', 'says',  # Common in translations but not useful mappings\n",
    "}\n",
    "\n",
    "# English words that indicate the Akkadian is probably a name\n",
    "NAME_INDICATORS = {'son', 'daughter', 'wife', 'seal', 'witness'}\n",
    "\n",
    "def tokenize_akk(text):\n",
    "    return text.split()\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return re.findall(r\"[a-z]+(?:'[a-z]+)?|\\d+\", text.lower())\n",
    "\n",
    "def is_number(w):\n",
    "    return bool(re.match(r'^[\\d.]+$', w))\n",
    "\n",
    "def is_logogram(w):\n",
    "    if w in LOGO_TO_ENGLISH:\n",
    "        return True\n",
    "    clean = re.sub(r'[₀-₉]', '', w)\n",
    "    return clean in LOGO_TO_ENGLISH\n",
    "\n",
    "def guess_type(eng):\n",
    "    if eng in ['refined', 'good', 'fine', 'bad', 'washed', 'black', 'white', 'pure', 'ordinary', 'quality']:\n",
    "        return 'quality'\n",
    "    elif eng in ['gave', 'received', 'paid', 'brought', 'sent', 'returned', 'pay', 'bring', 'send', \n",
    "                 'give', 'take', 'owe', 'owes', 'owed', 'taken', 'placed', 'went', 'came', 'settled']:\n",
    "        return 'verb'\n",
    "    elif eng in ['silver', 'gold', 'copper', 'tin', 'wool', 'textile', 'textiles', 'iron', 'lapis']:\n",
    "        return 'material'\n",
    "    elif eng in ['brother', 'father', 'mother', 'lord', 'slave', 'sister', 'uncle', 'servant']:\n",
    "        return 'relation'\n",
    "    elif eng in ['tablet', 'seal', 'document', 'letter', 'contract', 'certified', 'verdict']:\n",
    "        return 'document'\n",
    "    elif eng in ['house', 'city', 'colony', 'there', 'here', 'palace', 'gate', 'market']:\n",
    "        return 'place'\n",
    "    elif eng in ['shekel', 'shekels', 'mina', 'minas', 'talent', 'talents']:\n",
    "        return 'unit'\n",
    "    elif eng in ['interest', 'debt', 'price', 'profit', 'loss', 'capital', 'expenses']:\n",
    "        return 'financial'\n",
    "    elif eng in ['month', 'year', 'day', 'week', 'eponymy', 'time']:\n",
    "        return 'time'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "# ============================================================\n",
    "# PASS 1: IDENTIFY NAMES\n",
    "# ============================================================\n",
    "\n",
    "def identify_names(train_df):\n",
    "    \"\"\"\n",
    "    Find all words that appear immediately after NAME_MARKERS.\n",
    "    These are personal names and should NOT be in vocabulary.\n",
    "    \"\"\"\n",
    "    name_candidates = Counter()\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        akk_words = tokenize_akk(row['transliteration'])\n",
    "        \n",
    "        for i, word in enumerate(akk_words):\n",
    "            # Check if this word is a name marker\n",
    "            marker = None\n",
    "            if word in NAME_MARKERS:\n",
    "                marker = word\n",
    "            elif re.sub(r'[₀-₉]', '', word) in NAME_MARKERS:\n",
    "                marker = re.sub(r'[₀-₉]', '', word)\n",
    "            \n",
    "            if marker:\n",
    "                # Next word is a name\n",
    "                if i + 1 < len(akk_words):\n",
    "                    potential_name = akk_words[i + 1]\n",
    "                    if potential_name not in AKK_STOP and not is_number(potential_name):\n",
    "                        name_candidates[potential_name] += 1\n",
    "    \n",
    "    # Words that appear after name markers more than once are definitely names\n",
    "    names = {word for word, count in name_candidates.items() if count >= 1}\n",
    "    \n",
    "    return names\n",
    "\n",
    "# ============================================================\n",
    "# PASS 2: EXTRACT VOCABULARY (EXCLUDING NAMES)\n",
    "# ============================================================\n",
    "\n",
    "def extract_vocab(train_df, name_blacklist):\n",
    "    \"\"\"\n",
    "    Extract vocabulary using ±1 positional window.\n",
    "    Skip any word in name_blacklist.\n",
    "    \"\"\"\n",
    "    cooccur = defaultdict(Counter)\n",
    "    akk_counts = Counter()\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        akk_words = tokenize_akk(row['transliteration'])\n",
    "        eng_words = tokenize_eng(row['translation'])\n",
    "        \n",
    "        if len(akk_words) < 2 or len(eng_words) < 2:\n",
    "            continue\n",
    "        \n",
    "        for akk_idx, akk_word in enumerate(akk_words):\n",
    "            # SKIP IF NAME\n",
    "            if akk_word in name_blacklist:\n",
    "                continue\n",
    "            \n",
    "            # Skip stop words, numbers, logograms\n",
    "            if akk_word in AKK_STOP or is_number(akk_word) or is_logogram(akk_word):\n",
    "                continue\n",
    "            if len(akk_word) < 2:\n",
    "                continue\n",
    "            \n",
    "            akk_counts[akk_word] += 1\n",
    "            \n",
    "            # Positional alignment (±1 window)\n",
    "            ratio = akk_idx / len(akk_words)\n",
    "            eng_center = int(ratio * len(eng_words))\n",
    "            \n",
    "            for eng_idx in range(max(0, eng_center - 1), min(len(eng_words), eng_center + 2)):\n",
    "                eng_word = eng_words[eng_idx]\n",
    "                if eng_word not in ENG_STOP and len(eng_word) > 2:\n",
    "                    # Also skip if English word indicates this is probably a name context\n",
    "                    if eng_word not in NAME_INDICATORS:\n",
    "                        cooccur[akk_word][eng_word] += 1\n",
    "    \n",
    "    # Build vocab\n",
    "    vocab = {}\n",
    "    for akk, eng_counts in cooccur.items():\n",
    "        if akk_counts[akk] < 3:\n",
    "            continue\n",
    "        \n",
    "        top_eng, top_count = eng_counts.most_common(1)[0]\n",
    "        confidence = top_count / akk_counts[akk]\n",
    "        \n",
    "        if confidence >= 0.3 and top_count >= 3:\n",
    "            vocab[akk] = {\n",
    "                'translation': top_eng,\n",
    "                'confidence': round(confidence, 2),\n",
    "                'count': top_count,\n",
    "                'total': akk_counts[akk],\n",
    "                'alternatives': [(w, c) for w, c in eng_counts.most_common(5)[1:]],\n",
    "                'type': guess_type(top_eng),\n",
    "            }\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"=\"*60)\n",
    "    print(\"VOCAB EXTRACTOR v5 - NAME BLACKLISTING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    train = pd.read_csv('/kaggle/input/deep-past-initiative-machine-translation/train.csv')\n",
    "    print(f\"Loaded {len(train)} training sentences\")\n",
    "    \n",
    "    # PASS 1: Identify names\n",
    "    print(\"\\n--- Pass 1: Identifying names ---\")\n",
    "    names = identify_names(train)\n",
    "    print(f\"Found {len(names)} unique names (blacklisted from vocabulary)\")\n",
    "    \n",
    "    # Show sample names\n",
    "    print(\"\\nSample names (first 20):\")\n",
    "    for name in list(names)[:20]:\n",
    "        print(f\"  {name}\")\n",
    "    \n",
    "    # PASS 2: Extract vocabulary\n",
    "    print(\"\\n--- Pass 2: Extracting vocabulary ---\")\n",
    "    vocab = extract_vocab(train, names)\n",
    "    print(f\"Extracted {len(vocab)} vocabulary words\")\n",
    "    \n",
    "    # Group by type\n",
    "    by_type = defaultdict(list)\n",
    "    for word, data in vocab.items():\n",
    "        by_type[data['type']].append((word, data))\n",
    "    \n",
    "    for t in by_type:\n",
    "        by_type[t].sort(key=lambda x: -x[1]['count'])\n",
    "    \n",
    "    # Print by type\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VOCABULARY BY TYPE (copy to mycelial_translator.py)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for stype in ['verb', 'quality', 'relation', 'place', 'document', 'time', 'financial', 'material', 'unit', 'unknown']:\n",
    "        if stype not in by_type:\n",
    "            continue\n",
    "        words = by_type[stype]\n",
    "        if not words:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n# === {stype.upper()} ({len(words)} words) ===\")\n",
    "        for akk, data in words[:25]:  # Top 25 per type\n",
    "            eng = data['translation']\n",
    "            conf = data['confidence']\n",
    "            count = data['count']\n",
    "            alts = data.get('alternatives', [])[:2]\n",
    "            alt_str = f\" | alts: {[a[0] for a in alts]}\" if alts else \"\"\n",
    "            print(f\"    '{akk}': {{'meaning': '{eng}', 'type': '{stype}', 'confidence': {conf}}},  # {count}x{alt_str}\")\n",
    "    \n",
    "    # Print names for reference\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"NAMES BLACKLIST ({len(names)} total)\")\n",
    "    print(\"These are kept as transliteration, not translated\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Sort by frequency if we tracked it\n",
    "    print(\"\\nFirst 50 names:\")\n",
    "    for name in sorted(list(names))[:50]:\n",
    "        print(f\"  {name}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DONE\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64a99091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T05:36:52.150895Z",
     "iopub.status.busy": "2026-01-04T05:36:52.150247Z",
     "iopub.status.idle": "2026-01-04T05:36:52.217452Z",
     "shell.execute_reply": "2026-01-04T05:36:52.216529Z"
    },
    "papermill": {
     "duration": 0.07576,
     "end_time": "2026-01-04T05:36:52.219544",
     "exception": false,
     "start_time": "2026-01-04T05:36:52.143784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6648 words from extracted_vocab.json\n",
      "============================================================\n",
      "MYCELIALNET AKKADIAN TRANSLATOR\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SAMPLE TRANSLATIONS\n",
      "============================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "Akkadian: KIŠIB ma-nu-ba-lúm-a-šur DUMU ḫu-za-lúm\n",
      "Translation: seal of ma-nu-ba-lúm-a-šur son of ḫu-za-lúm\n",
      "Node breakdown:\n",
      "  KIŠIB                -> seal of              (document, 100%)\n",
      "  ma-nu-ba-lúm-a-šur   -> ma-nu-ba-lúm-a-šur   (name, 61%)\n",
      "  DUMU                 -> son of               (relation, 100%)\n",
      "  ḫu-za-lúm            -> ḫu-za-lúm            (name, 61%)\n",
      "\n",
      "--- Example 2 ---\n",
      "Akkadian: 10 MA.NA KÙ.BABBAR ṣa-ru-pá-am\n",
      "Translation: 10 mina silver refined\n",
      "Node breakdown:\n",
      "  10                   -> 10                   (number, 95%)\n",
      "  MA.NA                -> mina                 (unit, 100%)\n",
      "  KÙ.BABBAR            -> silver               (material, 100%)\n",
      "  ṣa-ru-pá-am          -> refined              (quality, 90%)\n",
      "\n",
      "--- Example 3 ---\n",
      "Akkadian: 1 ANŠE ṣa-lá-mu SIG₅\n",
      "Translation: 1 donkey black fine/good quality\n",
      "Node breakdown:\n",
      "  1                    -> 1                    (number, 95%)\n",
      "  ANŠE                 -> donkey               (animal, 100%)\n",
      "  ṣa-lá-mu             -> black                (color, 90%)\n",
      "  SIG₅                 -> fine/good quality    (quality, 100%)\n",
      "\n",
      "============================================================\n",
      "DONE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MYCELIALNET AKKADIAN TRANSLATOR - COMPLETE VERSION\n",
    "==================================================\n",
    "Inspired by Paolo Dell'Aversana's MycelialNet architecture.\n",
    "\n",
    "Instead of static positional lookup:\n",
    "  LOGOGRAM → check position ±1,2,3 → assign meaning\n",
    "\n",
    "We use distributed propagation:\n",
    "  Each word is a NODE that:\n",
    "  - Has initial confidence about its meaning\n",
    "  - Communicates with neighboring nodes\n",
    "  - Updates belief based on neighbor signals\n",
    "  - Converges to final interpretation\n",
    "\n",
    "Logograms are HIGH-CONFIDENCE SEED NODES that inject\n",
    "certainty into the network. Meaning propagates outward\n",
    "like nutrients through a mycelial network.\n",
    "\n",
    "Key principles from Paolo's work:\n",
    "1. Local rules → emergent global intelligence\n",
    "2. No central processor\n",
    "3. Adaptive connectivity based on context\n",
    "4. Resonance between compatible meanings\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# KNOWLEDGE BASE (Seeds for the network)\n",
    "# ============================================================\n",
    "\n",
    "# Logograms: 100% confidence anchor nodes\n",
    "LOGOGRAMS = {\n",
    "    'KÙ.BABBAR': {'meaning': 'silver', 'type': 'material', 'confidence': 1.0},\n",
    "    'KÙ.GI': {'meaning': 'gold', 'type': 'material', 'confidence': 1.0},\n",
    "    'URUDU': {'meaning': 'copper', 'type': 'material', 'confidence': 1.0},\n",
    "    'AN.NA': {'meaning': 'tin', 'type': 'material', 'confidence': 1.0},\n",
    "    'ZABAR': {'meaning': 'bronze', 'type': 'material', 'confidence': 1.0},\n",
    "    'GÍN': {'meaning': 'shekel', 'type': 'unit', 'confidence': 1.0},\n",
    "    'GÍN.TA': {'meaning': 'shekel each', 'type': 'unit', 'confidence': 1.0},\n",
    "    'MA.NA': {'meaning': 'mina', 'type': 'unit', 'confidence': 1.0},\n",
    "    'GÚ': {'meaning': 'talent', 'type': 'unit', 'confidence': 1.0},\n",
    "    'DUMU': {'meaning': 'son of', 'type': 'relation', 'confidence': 1.0},\n",
    "    'DUMU.MUNUS': {'meaning': 'daughter of', 'type': 'relation', 'confidence': 1.0},\n",
    "    'DAM': {'meaning': 'wife of', 'type': 'relation', 'confidence': 1.0},\n",
    "    'DAM.GÀR': {'meaning': 'merchant', 'type': 'profession', 'confidence': 1.0},\n",
    "    'KIŠIB': {'meaning': 'seal of', 'type': 'document', 'confidence': 1.0},\n",
    "    'É': {'meaning': 'house', 'type': 'structure', 'confidence': 1.0},\n",
    "    'ANŠE': {'meaning': 'donkey', 'type': 'animal', 'confidence': 1.0},\n",
    "    'TÚG': {'meaning': 'textile', 'type': 'goods', 'confidence': 1.0},\n",
    "    'TÚG.ḪI.A': {'meaning': 'textiles', 'type': 'goods', 'confidence': 1.0},\n",
    "    'UDU': {'meaning': 'sheep', 'type': 'animal', 'confidence': 1.0},\n",
    "    'SÍG': {'meaning': 'wool', 'type': 'material', 'confidence': 1.0},\n",
    "    'SÍG.ḪI.A': {'meaning': 'wool', 'type': 'material', 'confidence': 1.0},\n",
    "    'ITU': {'meaning': 'month', 'type': 'time', 'confidence': 1.0},\n",
    "    'ITU.KAM': {'meaning': 'month', 'type': 'time', 'confidence': 1.0},\n",
    "    'MU': {'meaning': 'year', 'type': 'time', 'confidence': 1.0},\n",
    "    'IGI': {'meaning': 'before/witnessed by', 'type': 'legal', 'confidence': 1.0},\n",
    "    'ŠU.NÍGIN': {'meaning': 'total', 'type': 'accounting', 'confidence': 1.0},\n",
    "    'SIG₅': {'meaning': 'fine/good quality', 'type': 'quality', 'confidence': 1.0},\n",
    "}\n",
    "\n",
    "# Semantic type compatibility matrix\n",
    "TYPE_COMPATIBILITY = {\n",
    "    'material': {'unit': 0.9, 'quality': 0.9, 'number': 0.8, 'verb': 0.5},\n",
    "    'unit': {'material': 0.9, 'number': 0.95, 'quality': 0.3},\n",
    "    'relation': {'name': 0.95, 'profession': 0.6},\n",
    "    'name': {'relation': 0.9, 'name': 0.7, 'legal': 0.6},\n",
    "    'number': {'unit': 0.95, 'material': 0.7, 'goods': 0.8, 'animal': 0.8},\n",
    "    'quality': {'material': 0.9, 'goods': 0.8, 'animal': 0.7},\n",
    "    'animal': {'quality': 0.8, 'number': 0.8, 'color': 0.9},\n",
    "    'color': {'animal': 0.9, 'goods': 0.7},\n",
    "    'goods': {'number': 0.8, 'quality': 0.8},\n",
    "    'time': {'name': 0.7, 'number': 0.8},\n",
    "    'legal': {'name': 0.9},\n",
    "    'document': {'name': 0.95},\n",
    "    'profession': {'name': 0.7, 'relation': 0.5},\n",
    "    'verb': {'name': 0.6, 'material': 0.6, 'number': 0.5},\n",
    "    'particle': {'any': 0.3},\n",
    "    'speech': {'name': 0.7, 'particle': 0.5},\n",
    "    'financial': {'material': 0.8, 'number': 0.7, 'unit': 0.6},\n",
    "    'accounting': {'number': 0.9, 'material': 0.7},\n",
    "    'structure': {'name': 0.6, 'place': 0.5},\n",
    "}\n",
    "\n",
    "# Known vocabulary with semantic types\n",
    "VOCABULARY = {\n",
    "    # Quality descriptors\n",
    "    'ṣa-ru-pá-am': {'meaning': 'refined', 'type': 'quality', 'confidence': 0.9},\n",
    "    'ṣa-ru-pu-um': {'meaning': 'refined', 'type': 'quality', 'confidence': 0.9},\n",
    "    'ṣa-ru-pí-im': {'meaning': 'refined', 'type': 'quality', 'confidence': 0.9},\n",
    "    \n",
    "    # Donkey colors\n",
    "    'ṣa-lá-mu': {'meaning': 'black', 'type': 'color', 'confidence': 0.9},\n",
    "    'ṣa-lá-ma-am': {'meaning': 'black', 'type': 'color', 'confidence': 0.9},\n",
    "    'ṣa-lá-me': {'meaning': 'black', 'type': 'color', 'confidence': 0.9},\n",
    "    'ṣa-la-mu': {'meaning': 'black', 'type': 'color', 'confidence': 0.9},\n",
    "    \n",
    "    # Copper qualities\n",
    "    'ší-kam': {'meaning': 'good (sikku)', 'type': 'quality', 'confidence': 0.85},\n",
    "    'ší-ku-um': {'meaning': 'good (sikku)', 'type': 'quality', 'confidence': 0.85},\n",
    "    'ma-sí-um': {'meaning': 'washed', 'type': 'quality', 'confidence': 0.85},\n",
    "    'ma-sí-im': {'meaning': 'washed', 'type': 'quality', 'confidence': 0.85},\n",
    "    'ma-sí-a-am': {'meaning': 'washed', 'type': 'quality', 'confidence': 0.85},\n",
    "    'lá-mu-num': {'meaning': 'refined', 'type': 'quality', 'confidence': 0.85},\n",
    "    'lá-mu-nam': {'meaning': 'refined', 'type': 'quality', 'confidence': 0.85},\n",
    "    \n",
    "    # Common verbs\n",
    "    'i-dí-in': {'meaning': 'he gave', 'type': 'verb', 'confidence': 0.8},\n",
    "    'a-dí-in': {'meaning': 'I gave', 'type': 'verb', 'confidence': 0.8},\n",
    "    'ni-dí-in': {'meaning': 'we gave', 'type': 'verb', 'confidence': 0.8},\n",
    "    'il₅-qé': {'meaning': 'he received', 'type': 'verb', 'confidence': 0.8},\n",
    "    'al-qé': {'meaning': 'I received', 'type': 'verb', 'confidence': 0.8},\n",
    "    'i-ša-qal': {'meaning': 'he will pay', 'type': 'verb', 'confidence': 0.8},\n",
    "    'iš-qúl': {'meaning': 'he paid', 'type': 'verb', 'confidence': 0.8},\n",
    "    'iš-qú-ul': {'meaning': 'he paid', 'type': 'verb', 'confidence': 0.8},\n",
    "    \n",
    "    # Particles\n",
    "    'ša': {'meaning': 'of/which', 'type': 'particle', 'confidence': 0.7},\n",
    "    'a-na': {'meaning': 'to/for', 'type': 'particle', 'confidence': 0.7},\n",
    "    'ù': {'meaning': 'and', 'type': 'particle', 'confidence': 0.7},\n",
    "    'ú': {'meaning': 'and', 'type': 'particle', 'confidence': 0.7},\n",
    "    'i-na': {'meaning': 'in/from', 'type': 'particle', 'confidence': 0.7},\n",
    "    'iš-tù': {'meaning': 'from/since', 'type': 'particle', 'confidence': 0.7},\n",
    "    'iš-tí': {'meaning': 'with', 'type': 'particle', 'confidence': 0.7},\n",
    "    'ki-ma': {'meaning': 'like/as', 'type': 'particle', 'confidence': 0.7},\n",
    "    'šu-ma': {'meaning': 'if', 'type': 'particle', 'confidence': 0.7},\n",
    "    \n",
    "    # Speech/communication\n",
    "    'um-ma': {'meaning': 'thus (says)', 'type': 'speech', 'confidence': 0.85},\n",
    "    'qí-bi-ma': {'meaning': 'speak!', 'type': 'speech', 'confidence': 0.85},\n",
    "    'qí-bi₄-ma': {'meaning': 'speak!', 'type': 'speech', 'confidence': 0.85},\n",
    "    \n",
    "    # Financial terms\n",
    "    'ṣí-ib-tám': {'meaning': 'interest', 'type': 'financial', 'confidence': 0.85},\n",
    "    'ṣí-ba-sú': {'meaning': 'his interest', 'type': 'financial', 'confidence': 0.85},\n",
    "    'qá-qá-ad': {'meaning': 'principal', 'type': 'financial', 'confidence': 0.85},\n",
    "    'ḫu-bu-ul': {'meaning': 'debt of', 'type': 'financial', 'confidence': 0.85},\n",
    "    \n",
    "    # Time/Calendar\n",
    "    'li-mu-um': {'meaning': 'eponymy (year)', 'type': 'time', 'confidence': 0.85},\n",
    "    'ḫa-muš-tim': {'meaning': 'week', 'type': 'time', 'confidence': 0.85},\n",
    "    'ḫa-mu-uš-tim': {'meaning': 'week', 'type': 'time', 'confidence': 0.85},\n",
    "    \n",
    "    # Places\n",
    "    'kà-ni-iš': {'meaning': 'Kanesh', 'type': 'place', 'confidence': 0.9},\n",
    "    'kà-ru-um': {'meaning': 'kārum (colony)', 'type': 'place', 'confidence': 0.85},\n",
    "    'a-lim': {'meaning': 'the City (Assur)', 'type': 'place', 'confidence': 0.85},\n",
    "    \n",
    "    # People terms\n",
    "    'a-ḫi': {'meaning': 'my brother', 'type': 'relation', 'confidence': 0.8},\n",
    "    'a-bi': {'meaning': 'my father', 'type': 'relation', 'confidence': 0.8},\n",
    "    'be-lí': {'meaning': 'my lord', 'type': 'relation', 'confidence': 0.8},\n",
    "    'um-me-a-nim': {'meaning': 'investor', 'type': 'profession', 'confidence': 0.8},\n",
    "}\n",
    "# Load extracted vocabulary\n",
    "import json\n",
    "try:\n",
    "    with open('extracted_vocab.json', 'r', encoding='utf-8') as f:\n",
    "        extracted = json.load(f)\n",
    "    \n",
    "    # Merge into VOCABULARY\n",
    "    for word, data in extracted.items():\n",
    "        if word not in VOCABULARY:\n",
    "            VOCABULARY[word] = {\n",
    "                'meaning': data['meaning'],\n",
    "                'type': data.get('type', 'unknown'),\n",
    "                'confidence': data['confidence']\n",
    "            }\n",
    "    \n",
    "    print(f\"Loaded {len(extracted)} words from extracted_vocab.json\")\n",
    "except:\n",
    "    print(\"No extracted vocab found, using base vocabulary only\")\n",
    "# ============================================================\n",
    "# WORD NODE CLASS\n",
    "# ============================================================\n",
    "\n",
    "class WordNode:\n",
    "    \"\"\"\n",
    "    A node in the mycelial network.\n",
    "    Each word is a node that:\n",
    "    - Holds beliefs about its meaning\n",
    "    - Communicates with neighbors\n",
    "    - Updates based on network signals\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, word, position):\n",
    "        self.word = word\n",
    "        self.position = position\n",
    "        self.neighbors = []\n",
    "        \n",
    "        # Initialize beliefs\n",
    "        self.beliefs = {}\n",
    "        self.semantic_type = None\n",
    "        self.is_anchor = False\n",
    "        \n",
    "        # Check if it's a known word\n",
    "        self._initialize_beliefs()\n",
    "    \n",
    "    def _initialize_beliefs(self):\n",
    "        \"\"\"Set initial beliefs based on knowledge base\"\"\"\n",
    "        \n",
    "        # Check if logogram\n",
    "        if self.word in LOGOGRAMS:\n",
    "            data = LOGOGRAMS[self.word]\n",
    "            self.beliefs = {data['meaning']: data['confidence']}\n",
    "            self.semantic_type = data['type']\n",
    "            self.is_anchor = True\n",
    "            return\n",
    "        \n",
    "        # Check subscript variants\n",
    "        clean = re.sub(r'[₀-₉]', '', self.word)\n",
    "        if clean in LOGOGRAMS:\n",
    "            data = LOGOGRAMS[clean]\n",
    "            self.beliefs = {data['meaning']: data['confidence']}\n",
    "            self.semantic_type = data['type']\n",
    "            self.is_anchor = True\n",
    "            return\n",
    "        \n",
    "        # Check vocabulary\n",
    "        if self.word in VOCABULARY:\n",
    "            data = VOCABULARY[self.word]\n",
    "            self.beliefs = {data['meaning']: data['confidence']}\n",
    "            self.semantic_type = data['type']\n",
    "            return\n",
    "        \n",
    "        # Check if number\n",
    "        if re.match(r'^[\\d.]+$', self.word):\n",
    "            self.beliefs = {self.word: 0.95}\n",
    "            self.semantic_type = 'number'\n",
    "            return\n",
    "        \n",
    "        # Unknown word - start with uncertainty\n",
    "        self.beliefs = {self.word: 0.3}\n",
    "        self.semantic_type = 'unknown'\n",
    "    \n",
    "    def get_best_belief(self):\n",
    "        \"\"\"Return highest confidence meaning\"\"\"\n",
    "        if not self.beliefs:\n",
    "            return self.word, 0.0\n",
    "        \n",
    "        # Filter out inference tracking keys\n",
    "        actual_beliefs = {k: v for k, v in self.beliefs.items() \n",
    "                          if not k.endswith('_inference') and not k.endswith('_candidate')}\n",
    "        \n",
    "        if not actual_beliefs:\n",
    "            return self.word, 0.3\n",
    "        \n",
    "        best = max(actual_beliefs.items(), key=lambda x: x[1])\n",
    "        return best\n",
    "    \n",
    "    def receive_signal(self, sender_type, sender_meaning, signal_strength):\n",
    "        \"\"\"\n",
    "        Receive a signal from a neighbor node.\n",
    "        Update beliefs based on semantic compatibility.\n",
    "        \"\"\"\n",
    "        if self.is_anchor:\n",
    "            return\n",
    "        \n",
    "        if self.semantic_type == 'unknown':\n",
    "            self._infer_from_context(sender_type, sender_meaning, signal_strength)\n",
    "    \n",
    "    def _infer_from_context(self, neighbor_type, neighbor_meaning, strength):\n",
    "        \"\"\"\n",
    "        Systematic inference using TYPE_COMPATIBILITY matrix.\n",
    "        Geological facies correlation engine.\n",
    "        \"\"\"\n",
    "        if self.is_anchor:\n",
    "            return\n",
    "        \n",
    "        # Get compatible types for this neighbor\n",
    "        if neighbor_type not in TYPE_COMPATIBILITY:\n",
    "            return\n",
    "        \n",
    "        compatible_types = TYPE_COMPATIBILITY[neighbor_type]\n",
    "        \n",
    "        # Propagate belief to compatible semantic types\n",
    "        for possible_type, compatibility_score in compatible_types.items():\n",
    "            if possible_type == 'any':\n",
    "                continue\n",
    "            \n",
    "            # Calculate belief boost\n",
    "            boost = strength * compatibility_score * 0.4\n",
    "            \n",
    "            # Create or update belief for this type\n",
    "            belief_key = f\"{possible_type}_inference\"\n",
    "            \n",
    "            if belief_key not in self.beliefs:\n",
    "                self.beliefs[belief_key] = boost\n",
    "            else:\n",
    "                self.beliefs[belief_key] = min(0.95, self.beliefs[belief_key] + boost)\n",
    "            \n",
    "            # If confidence crosses threshold, assign the semantic type\n",
    "            if self.beliefs[belief_key] > 0.6 and self.semantic_type == 'unknown':\n",
    "                self.semantic_type = possible_type\n",
    "                self.beliefs[self.word] = self.beliefs[belief_key]\n",
    "    \n",
    "    def propagate(self):\n",
    "        \"\"\"\n",
    "        Send signals to all neighbors.\n",
    "        Returns list of (neighbor, signal) tuples.\n",
    "        \"\"\"\n",
    "        if not self.beliefs:\n",
    "            return []\n",
    "        \n",
    "        meaning, confidence = self.get_best_belief()\n",
    "        \n",
    "        # Signal strength decays with uncertainty\n",
    "        signal_strength = confidence * 0.8\n",
    "        \n",
    "        signals = []\n",
    "        for neighbor in self.neighbors:\n",
    "            signals.append((neighbor, self.semantic_type, meaning, signal_strength))\n",
    "        \n",
    "        return signals\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MYCELIAL NETWORK CLASS\n",
    "# ============================================================\n",
    "\n",
    "class MycelialNetwork:\n",
    "    \"\"\"\n",
    "    A network of word nodes that propagate meaning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, words):\n",
    "        \"\"\"Build network from word list\"\"\"\n",
    "        self.nodes = []\n",
    "        \n",
    "        # Create nodes\n",
    "        for i, word in enumerate(words):\n",
    "            node = WordNode(word, i)\n",
    "            self.nodes.append(node)\n",
    "        \n",
    "        # Connect neighbors (bidirectional, within window)\n",
    "        window_size = 3\n",
    "        for i, node in enumerate(self.nodes):\n",
    "            for j in range(max(0, i - window_size), min(len(self.nodes), i + window_size + 1)):\n",
    "                if i != j:\n",
    "                    node.neighbors.append(self.nodes[j])\n",
    "    \n",
    "    def propagate_iteration(self):\n",
    "        \"\"\"\n",
    "        One iteration of signal propagation.\n",
    "        All nodes send signals simultaneously, then update.\n",
    "        \"\"\"\n",
    "        # Collect all signals\n",
    "        all_signals = []\n",
    "        for node in self.nodes:\n",
    "            signals = node.propagate()\n",
    "            all_signals.extend(signals)\n",
    "        \n",
    "        # Apply signals\n",
    "        for receiver, sender_type, sender_meaning, strength in all_signals:\n",
    "            receiver.receive_signal(sender_type, sender_meaning, strength)\n",
    "    \n",
    "    def converge(self, max_iterations=5):\n",
    "        \"\"\"\n",
    "        Run propagation until convergence or max iterations.\n",
    "        \"\"\"\n",
    "        for i in range(max_iterations):\n",
    "            self.propagate_iteration()\n",
    "    \n",
    "    def get_translation(self):\n",
    "        \"\"\"\n",
    "        Extract final translation from converged network.\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for node in self.nodes:\n",
    "            meaning, confidence = node.get_best_belief()\n",
    "            \n",
    "            # Clean up candidate markers\n",
    "            if meaning.endswith('_candidate'):\n",
    "                meaning = node.word\n",
    "            \n",
    "            result.append({\n",
    "                'original': node.word,\n",
    "                'translation': meaning,\n",
    "                'confidence': confidence,\n",
    "                'type': node.semantic_type,\n",
    "            })\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRANSLATOR CLASS\n",
    "# ============================================================\n",
    "\n",
    "class MycelialTranslator:\n",
    "    \"\"\"\n",
    "    Full translator using mycelial network approach.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stats = defaultdict(int)\n",
    "    \n",
    "    def translate(self, akkadian_text):\n",
    "        \"\"\"Translate a single sentence\"\"\"\n",
    "        \n",
    "        # Tokenize\n",
    "        words = akkadian_text.split()\n",
    "        \n",
    "        # Build network\n",
    "        network = MycelialNetwork(words)\n",
    "        \n",
    "        # Propagate until convergence\n",
    "        network.converge(max_iterations=5)\n",
    "        \n",
    "        # Extract results\n",
    "        node_results = network.get_translation()\n",
    "        \n",
    "        # Build output string\n",
    "        output_words = []\n",
    "        for res in node_results:\n",
    "            self.stats[res['type']] += 1\n",
    "            output_words.append(res['translation'])\n",
    "        \n",
    "        return ' '.join(output_words)\n",
    "    \n",
    "    def translate_batch(self, texts):\n",
    "        \"\"\"Translate multiple sentences\"\"\"\n",
    "        return [self.translate(t) for t in texts]\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return dict(self.stats)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"=\"*60)\n",
    "    print(\"MYCELIALNET AKKADIAN TRANSLATOR\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test with sample sentences\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SAMPLE TRANSLATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Sample Akkadian sentences\n",
    "    samples = [\n",
    "        \"KIŠIB ma-nu-ba-lúm-a-šur DUMU ḫu-za-lúm\",\n",
    "        \"10 MA.NA KÙ.BABBAR ṣa-ru-pá-am\",\n",
    "        \"1 ANŠE ṣa-lá-mu SIG₅\",\n",
    "    ]\n",
    "    \n",
    "    translator = MycelialTranslator()\n",
    "    \n",
    "    for idx, akkadian in enumerate(samples):\n",
    "        print(f\"\\n--- Example {idx + 1} ---\")\n",
    "        print(f\"Akkadian: {akkadian}\")\n",
    "        \n",
    "        # Build network for visualization\n",
    "        words = akkadian.split()\n",
    "        network = MycelialNetwork(words)\n",
    "        network.converge()\n",
    "        \n",
    "        result = network.get_translation()\n",
    "        trans = ' '.join([r['translation'] for r in result])\n",
    "        print(f\"Translation: {trans}\")\n",
    "        \n",
    "        # Show node details\n",
    "        print(\"Node breakdown:\")\n",
    "        for r in result:\n",
    "            print(f\"  {r['original']:20} -> {r['translation']:20} ({r['type']}, {r['confidence']:.0%})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DONE\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15061024,
     "sourceId": 121150,
     "sourceType": "competition"
    },
    {
     "sourceId": 289577555,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 289765048,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.862439,
   "end_time": "2026-01-04T05:36:52.744311",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-04T05:36:42.881872",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
